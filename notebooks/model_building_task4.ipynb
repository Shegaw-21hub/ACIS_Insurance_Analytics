{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Project\\ACIS_Insurance_Analytics\\notebooks\n",
      "scikit-learn version: 1.7.0\n",
      "Preprocessed data loaded successfully!\n",
      "Training data shape: (1951, 8)\n",
      "Test data shape: (837, 8)\n",
      "\n",
      "Building models...\n",
      "\n",
      "==================================================\n",
      "MODEL EVALUATION\n",
      "==================================================\n",
      "\n",
      "LinearRegression:\n",
      "- RMSE: 33922.89\n",
      "- R2: 0.27\n",
      "\n",
      "RandomForest:\n",
      "- RMSE: 34663.72\n",
      "- R2: 0.24\n",
      "\n",
      "XGBoost:\n",
      "- RMSE: 37797.74\n",
      "- R2: 0.09\n",
      "\n",
      "Best model: LinearRegression\n",
      "\n",
      "Saved best model (LinearRegression) to output/best_model.joblib\n",
      "\n",
      "==================================================\n",
      "MODEL BUILDING COMPLETED SUCCESSFULLY!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "import os\n",
    "print(os.getcwd())\n",
    " \n",
    "\n",
    "# 1. LOAD PREPROCESSED DATA ==================================================\n",
    "\n",
    "def load_preprocessed_data():\n",
    "    \"\"\"Load all artifacts from preprocessing\"\"\"\n",
    "    try:\n",
    "        # Load preprocessor\n",
    "        preprocessor = joblib.load('output/preprocessor.joblib')\n",
    "        \n",
    "        # Load data splits\n",
    "        X_train = pd.read_csv('output/X_train.csv')\n",
    "        X_test = pd.read_csv('output/X_test.csv')\n",
    "        y_train = pd.read_csv('output/y_train.csv').squeeze()\n",
    "        y_test = pd.read_csv('output/y_test.csv').squeeze()\n",
    "        \n",
    "        print(\"Preprocessed data loaded successfully!\")\n",
    "        print(f\"Training data shape: {X_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}\")\n",
    "        \n",
    "        return preprocessor, X_train, X_test, y_train, y_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\nERROR LOADING PREPROCESSED DATA:\", str(e))\n",
    "        print(\"\\nTROUBLESHOOTING:\")\n",
    "        print(\"1. Make sure you ran preprocess_task4.py first\")\n",
    "        print(\"2. Verify 'output' directory exists with these files:\")\n",
    "        print(\"   - preprocessor.joblib\")\n",
    "        print(\"   - X_train.csv, X_test.csv\")\n",
    "        print(\"   - y_train.csv, y_test.csv\")\n",
    "        print(\"3. Check paths are correct\")\n",
    "        raise\n",
    "\n",
    "# 2. MODEL BUILDING ==========================================================\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE compatible with all sklearn versions\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def build_models(preprocessor, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Build and evaluate multiple models\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Linear Regression\n",
    "    lr_pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    lr_pipe.fit(X_train, y_train)\n",
    "    y_pred = lr_pipe.predict(X_test)\n",
    "    results['LinearRegression'] = {\n",
    "        'RMSE': calculate_rmse(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "        'model': lr_pipe\n",
    "    }\n",
    "    \n",
    "    # Random Forest\n",
    "    rf_pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    rf_pipe.fit(X_train, y_train)\n",
    "    y_pred = rf_pipe.predict(X_test)\n",
    "    results['RandomForest'] = {\n",
    "        'RMSE': calculate_rmse(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "        'model': rf_pipe\n",
    "    }\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "    ])\n",
    "    xgb_pipe.fit(X_train, y_train)\n",
    "    y_pred = xgb_pipe.predict(X_test)\n",
    "    results['XGBoost'] = {\n",
    "        'RMSE': calculate_rmse(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "        'model': xgb_pipe\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 3. MODEL EVALUATION ========================================================\n",
    "\n",
    "def evaluate_models(results, y_test):\n",
    "    \"\"\"Evaluate and compare model performance\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODEL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Print metrics\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"- RMSE: {metrics['RMSE']:.2f}\")\n",
    "        print(f\"- R2: {metrics['R2']:.2f}\")\n",
    "    \n",
    "    # Plot feature importance for best model\n",
    "    best_model_name = max(results.items(), key=lambda x: x[1]['R2'])[0]\n",
    "    best_model = results[best_model_name]['model']\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name}\")\n",
    "    \n",
    "    # SHAP analysis for interpretability\n",
    "    if hasattr(best_model.named_steps['regressor'], 'feature_importances_'):\n",
    "        explain_model(best_model, X_test)\n",
    "\n",
    "def explain_model(model, X_test):\n",
    "    \"\"\"Explain model using SHAP values\"\"\"\n",
    "    print(\"\\nGenerating SHAP explanations...\")\n",
    "    \n",
    "    try:\n",
    "        # Process test data through preprocessor\n",
    "        preprocessor = model.named_steps['preprocessor']\n",
    "        X_test_processed = preprocessor.transform(X_test)\n",
    "        \n",
    "        # Get feature names\n",
    "        numeric_features = preprocessor.named_transformers_['num'].features\n",
    "        categorical_features = preprocessor.named_transformers_['cat'].features\n",
    "        \n",
    "        # Get categorical feature names after one-hot encoding\n",
    "        cat_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_feature_names = cat_encoder.get_feature_names_out(categorical_features)\n",
    "        \n",
    "        all_features = numeric_features + list(cat_feature_names)\n",
    "        \n",
    "        # SHAP analysis\n",
    "        explainer = shap.Explainer(model.named_steps['regressor'])\n",
    "        shap_values = explainer.shap_values(X_test_processed)\n",
    "        \n",
    "        # Summary plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values, X_test_processed, feature_names=all_features)\n",
    "        plt.title(f'Feature Importance - SHAP Values')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('output/shap_summary.png')\n",
    "        print(\"Saved SHAP summary plot to output/shap_summary.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not generate SHAP explanations: {str(e)}\")\n",
    "\n",
    "# MAIN EXECUTION =============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Print version info for debugging\n",
    "        print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "        \n",
    "        # 1. Load preprocessed data\n",
    "        preprocessor, X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "        \n",
    "        # 2. Build models\n",
    "        print(\"\\nBuilding models...\")\n",
    "        results = build_models(preprocessor, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        # 3. Evaluate models\n",
    "        evaluate_models(results, y_test)\n",
    "        \n",
    "        # 4. Save best model\n",
    "        best_model_name = max(results.items(), key=lambda x: x[1]['R2'])[0]\n",
    "        joblib.dump(results[best_model_name]['model'], 'output/best_model.joblib')\n",
    "        print(f\"\\nSaved best model ({best_model_name}) to output/best_model.joblib\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"MODEL BUILDING COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"MODEL BUILDING FAILED:\", str(e))\n",
    "        print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
